{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9a4c0b1e",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJCordhose/ml-resources/blob/main/notebooks/foundation/transformers-sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "912d7d82",
      "metadata": {
        "id": "912d7d82"
      },
      "source": [
        "# Transformers: sentiment analysis using pretrained models\n",
        "\n",
        "* https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment\n",
        "* https://huggingface.co/facebook/bart-large-mnli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "BhKtZIx7BC8S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BhKtZIx7BC8S",
        "outputId": "b9af6c27-b38d-4c13-c2d5-f411d473ecaa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.8.0'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "PCzzSt7XAuBn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCzzSt7XAuBn",
        "outputId": "fcb235ae-dc45-4145-a6b6-5c164220e73a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# when we are not training, we do not need a GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "17bc5a59",
      "metadata": {
        "id": "17bc5a59"
      },
      "outputs": [],
      "source": [
        "# https://huggingface.co/transformers/installation.html\n",
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "UKkytQc2Al0y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UKkytQc2Al0y",
        "outputId": "20f42730-5d66-44c0-a02f-c6b128c7a5e9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.18.0'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "lyoLhh04GJDd",
      "metadata": {
        "id": "lyoLhh04GJDd"
      },
      "outputs": [],
      "source": [
        "sequence_0 = \"I don't think its a good idea to have people driving 40 miles an hour through a light that *just* turned green, especially with the number of people running red lights, or the number of pedestrians running across at the last minute being obscured by large cars in the lanes next to you.\"\n",
        "sequence_1 = 'MANY YEARS ago, When I was a teenager, I delivered pizza. I had a friend who, just for the fun of it, had a CB. While on a particular channel, he could key the mike with quick taps and make the light right out in front of the pizza place turn green. It was the only light that it worked on, and I was in the car with him numerous times to confirm that it worked. It was sweet.'\n",
        "sequence_2 = 'The \"green\" thing to do is not to do anything ever, don\\'t even breath!  Oh, and if you are not going to take that ridiculous standpoint then I guess this is relevant to Green because it uses Bio-fuels in one of the most harsh environments in the world, showing that dependence on tradition fuels is a choice not a necessity.'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Zr_WePTIF9t3",
      "metadata": {
        "id": "Zr_WePTIF9t3"
      },
      "source": [
        "## bert-base-multilingual-uncased-sentiment\n",
        "\n",
        "Version for TensorFlow\n",
        "\n",
        "https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "G97_wuf6D0-j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G97_wuf6D0-j",
        "outputId": "ac5a84f1-4974-4cfe-a5db-2e777b558cd7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 8.82 s, sys: 1.27 s, total: 10.1 s\n",
            "Wall time: 13.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time \n",
        "\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "model.name_or_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2Ooej9E_Effc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ooej9E_Effc",
        "outputId": "d62a71f4-1d94-4c5e-c78c-3d099bf06480"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
              " array([[ 1.8335618 ,  0.9494924 , -0.21574138, -1.1014451 , -1.1619096 ]],\n",
              "       dtype=float32)>,\n",
              " array([0.60787815, 0.2511135 , 0.07830969, 0.03229678, 0.03040184],\n",
              "       dtype=float32),\n",
              " 1)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# paraphrase = tokenizer(sequence_0, return_tensors=\"tf\")\n",
        "# paraphrase = tokenizer(sequence_1, return_tensors=\"tf\")\n",
        "paraphrase = tokenizer(sequence_2, return_tensors=\"tf\")\n",
        "\n",
        "paraphrase_classification_logits = model(paraphrase)[0]\n",
        "paraphrase_results = tf.nn.softmax(paraphrase_classification_logits, axis=1).numpy()[0]\n",
        "stars = paraphrase_results.argmax() + 1\n",
        "paraphrase_classification_logits, paraphrase_results, stars"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c944ksPG0Yl",
      "metadata": {
        "id": "1c944ksPG0Yl"
      },
      "source": [
        "## bart-large-mnli\n",
        "\n",
        "Version for Pytorch (TensorFlow is not available)\n",
        "\n",
        "https://huggingface.co/facebook/bart-large-mnli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cHz8m-8rIYlW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHz8m-8rIYlW",
        "outputId": "3337d197-dd0b-4120-a459-8966a1457775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 5.88 s, sys: 1.99 s, total: 7.87 s\n",
            "Wall time: 13.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from transformers import pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\",\n",
        "                      model=\"facebook/bart-large-mnli\")\n",
        "classifier.model.name_or_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "rAzaQ7P0ImpN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAzaQ7P0ImpN",
        "outputId": "14817a99-937e-42a0-a887-5de6411123bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'labels': ['ironic', 'negative', 'positive'],\n",
              " 'scores': [0.9157786965370178, 0.5182933807373047, 0.1775151491165161],\n",
              " 'sequence': 'The \"green\" thing to do is not to do anything ever, don\\'t even breath!  Oh, and if you are not going to take that ridiculous standpoint then I guess this is relevant to Green because it uses Bio-fuels in one of the most harsh environments in the world, showing that dependence on tradition fuels is a choice not a necessity.'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# sequence_to_classify = sequence_0\n",
        "# sequence_to_classify = sequence_1\n",
        "sequence_to_classify = sequence_2\n",
        "\n",
        "candidate_labels = ['positive', 'negative', 'ironic']\n",
        "classifier(sequence_to_classify, candidate_labels, multi_label=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "transformers-sentiment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
